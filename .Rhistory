for (j in 1 :nrow(data_na_resolution)){
if(data_samples[j,i]!=0){
# if NA_resolution did not existed, and the two weeks were samples normally, there is what you would have expected as the sum of shell of the two consecutives samples
total_shells <- 2*data_samples[j,i]
rows_to_sample <- which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
if(length(rows_to_sample)==0){print(j);print(total_shells)}
diff_distrib <- list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
# repeat until both samplings are positive values (= shell flux always positive)
set.seed(42) #for reproducibility
while(TRUE){
peteleco <- sample(diff_distrib,1)
sample1 <- data_samples[j,i]+peteleco
sample2 <- data_samples[j,i]-peteleco
if(sample1>=0 && sample2>=0) break()
}
time_step1 <- data_samples[j,"time_step"]
time_step2 <- data_na_resolution[j,"time_step"]
if(sample1+sample2!=total_shells){"Check code!"}
data[which(data$time_step==time_step1),i] <- sample1
data[which(data$time_step==time_step2),i] <- sample2
rm(rows_to_sample,diff_distrib,peteleco,sample1,sample2)
}else{ # if 0 shells were sampled
time_step2 <- data_na_resolution[j,"time_step"]
data[which(data$time_step==time_step2),i] <- data_samples[j,i]
}
}
data.frame(save, data[,i])
any(data[,i]<0)
any(data[,i]<0)
data[,i]
any(data[,i]<0, na.rm = T)
write.csv(data, "data/GOM/GOM_edm_ready.csv", row.names = FALSE)
rm(list=ls())
setwd("/Users/marinacostarillo/Google Drive/PhD/projects")
setwd("./time-series-forams/")
# Libraries
# source("R/library.R")
library(R.utils)   # sourceDirectory function
library(lubridate) # date calculations
library(GGally)    # ggpairs function
library(tseries)   # tests series stationary
library(ggplot2)   # plots
library(reshape)   # function melt
library(corrplot)  # matrix correlation plot
# Auxiliary functions
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
###
### Data
###
trap_name <- c("GOM") # Gulf of Mexico sediment trap
# Creating output folder for this sediment trap
if (!file.exists(paste("output/",trap_name,sep=""))){ dir.create(paste("output/",trap_name,"/",sep=""))}
# Time-series data
if(trap_name == "GOM"){
raw_data <- get_gom_sst(overwrite = F) # gets temperature data for the GOM time-series
raw_data<- raw_data[86:nrow(raw_data),] # removing first part of GOM time-series with big gaps (next_open = 123 and 21)
}# Other sediment traps: else{raw_data <- get_trap_data(overwrite = F)} # still write "get_trap_data" function
# Data to use
data <- raw_data[,-c(2:7)] # or <- datafd
data$open <- ymd(data$open) # transforming to date format (lubridate pkg)
# Plot scatterplot of everything
# ggpairs(data[,2:ncol(data)])
# First differences time-series
datafd <- get_first_diff(raw_data, trap_name, days_closed = 10,overwrite = F)
# days_closed : maximum number of days inbetween samples,if that gap between two samples is bigger than 10 days (next_open > 10 days), then the difference between these two samples is not included
library(rEDM)
library(zoo)
###### DATA ######
# GOM_NAs.csv : Gulf of Mexico sediment trap data with continuous time-steps and "NA" for intervals without data, see "README.txt" in data folder
data_na <- read.csv("data/GOM/GOM_NAs.csv", header = T, na = "NA")
# changing format to date
data_na$open <- dmy(data_na$open)
data_na$close <- dmy(data_na$close)
# tranfoming columns into numeric, NA_resolution and NA_gap will be transformed into NA (warnings())
data_na[, c(5:ncol(data_na))] <- sapply(data_na[, c(5:ncol(data_na))], function(x) as.numeric(as.character(x)))
# Calculating the distribution of sums and differences between consecutives samples (less than 'days_closed' apart)
distrib_list <- get_distrib_diffs(data_na, trap_name,  days_closed=7 ,overwrite = F)
# Filling in the NA_resolutions
data_use <- estimate_na_resolution <- function(data_na, distrib_list, overwrite = F)
]]]]]]
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
distrib_list <- get_distrib_diffs(data_na, trap_name,  days_closed=7 ,overwrite = F)
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
rm(list=ls())
setwd("/Users/marinacostarillo/Google Drive/PhD/projects")
setwd("./time-series-forams/")
# Libraries
# source("R/library.R")
library(R.utils)   # sourceDirectory function
library(lubridate) # date calculations
library(GGally)    # ggpairs function
library(tseries)   # tests series stationary
library(ggplot2)   # plots
library(reshape)   # function melt
library(corrplot)  # matrix correlation plot
# Auxiliary functions
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
###
### Data
###
trap_name <- c("GOM") # Gulf of Mexico sediment trap
#####################################
### EDM analysis: GOM time-series ###
#####################################
library(rEDM)
library(zoo)
###### DATA ######
# GOM_NAs.csv : Gulf of Mexico sediment trap data with continuous time-steps and "NA" for intervals without data, see "README.txt" in data folder
data_na <- read.csv("data/GOM/GOM_NAs.csv", header = T, na = "NA")
# changing format to date
data_na$open <- dmy(data_na$open)
data_na$close <- dmy(data_na$close)
# tranfoming columns into numeric, NA_resolution and NA_gap will be transformed into NA (warnings())
data_na[, c(5:ncol(data_na))] <- sapply(data_na[, c(5:ncol(data_na))], function(x) as.numeric(as.character(x)))
# Calculating the distribution of sums and differences between consecutives samples (less than 'days_closed' apart)
distrib_list <- get_distrib_diffs(data_na, trap_name,  days_closed=7 ,overwrite = F)
# Filling in the NA_resolutions
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
!file.exists("data/GOM/GOM_edm_ready.csv")
data_na_resolution <- data[duplicated(data$open),]
list <- distrib_list
data <- data_na
data_na_resolution <- data[duplicated(data$open),]
samples_resolution <- as.numeric(as.character(rownames(data_na_resolution)))-1
data_samples <- data[samples_resolution,]
i = 5
5:(ncol(data_na_resolution)-1)
for (j in 1 :nrow(data_na_resolution)){
if(data_samples[j,i]!=0){
# if NA_resolution did not existed, and the two weeks were samples normally, there is what you would have expected as the sum of shell of the two consecutives samples
total_shells <- 2*data_samples[j,i]
rows_to_sample <- which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
diff_distrib <- list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
# repeat until both samplings are positive values (= shell flux always positive)
set.seed(42) #for reproducibility
while(TRUE){
peteleco <- sample(diff_distrib,1)
sample1 <- data_samples[j,i]+peteleco
sample2 <- data_samples[j,i]-peteleco
if(sample1>=0 && sample2>=0) break()
}
time_step1 <- data_samples[j,"time_step"]
time_step2 <- data_na_resolution[j,"time_step"]
if(sample1+sample2!=total_shells){"Check code 1"}
data[which(data$time_step==time_step1),i] <- sample1
data[which(data$time_step==time_step2),i] <- sample2
rm(rows_to_sample,diff_distrib,peteleco,sample1,sample2)
}else{ # if 0 shells were sampled
time_step2 <- data_na_resolution[j,"time_step"]
data[which(data$time_step==time_step2),i] <- data_samples[j,i]
}
}
if(any(data[,i]<0, na.rm = T)){"Check code 2"}
print(names(data)[i])
rm(list=ls())
setwd("/Users/marinacostarillo/Google Drive/PhD/projects")
setwd("./time-series-forams/")
# Libraries
# source("R/library.R")
library(R.utils)   # sourceDirectory function
library(lubridate) # date calculations
library(GGally)    # ggpairs function
library(tseries)   # tests series stationary
library(ggplot2)   # plots
library(reshape)   # function melt
library(corrplot)  # matrix correlation plot
# Auxiliary functions
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
###
### Data
###
trap_name <- c("GOM") # Gulf of Mexico sediment trap
# Creating output folder for this sediment trap
if (!file.exists(paste("output/",trap_name,sep=""))){ dir.create(paste("output/",trap_name,"/",sep=""))}
# Time-series data
if(trap_name == "GOM"){
raw_data <- get_gom_sst(overwrite = F) # gets temperature data for the GOM time-series
raw_data<- raw_data[86:nrow(raw_data),] # removing first part of GOM time-series with big gaps (next_open = 123 and 21)
}# Other sediment traps: else{raw_data <- get_trap_data(overwrite = F)} # still write "get_trap_data" function
# Data to use
data <- raw_data[,-c(2:7)] # or <- datafd
data$open <- ymd(data$open) # transforming to date format (lubridate pkg)
# Plot scatterplot of everything
# ggpairs(data[,2:ncol(data)])
library(rEDM)
library(zoo)
###### DATA ######
# GOM_NAs.csv : Gulf of Mexico sediment trap data with continuous time-steps and "NA" for intervals without data, see "README.txt" in data folder
data_na <- read.csv("data/GOM/GOM_NAs.csv", header = T, na = "NA")
# changing format to date
data_na$open <- dmy(data_na$open)
data_na$close <- dmy(data_na$close)
# tranfoming columns into numeric, NA_resolution and NA_gap will be transformed into NA (warnings())
data_na[, c(5:ncol(data_na))] <- sapply(data_na[, c(5:ncol(data_na))], function(x) as.numeric(as.character(x)))
# Calculating the distribution of sums and differences between consecutives samples (less than 'days_closed' apart)
distrib_list <- get_distrib_diffs(data_na, trap_name,  days_closed=7 ,overwrite = F)
# Filling in the NA_resolutions
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
names(data)
names(data_na)
i=12
data <- data_na
list <- distrib_list
j=13
total_shells <- 2*data_samples[j,i]
# time-steps that need to be estimated
data_na_resolution <- data[duplicated(data$open),]
# samples averaged throughout the 14 days
samples_resolution <- as.numeric(as.character(rownames(data_na_resolution)))-1
data_samples <- data[samples_resolution,]
2*data_samples[j,i]
total_shells <- 2*data_samples[j,i]
rows_to_sample <- which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
rows_to_sample
list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]
diff_distrib <- list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
diff_distrib
sample(diff_distrib,1)
data_samples[j,i]
data_samples[j,i]+peteleco
peteleco <- sample(diff_distrib,1)
sample1 <- data_samples[j,i]+peteleco
sample2 <- data_samples[j,i]-peteleco
peteleco
sample1
sample2
peteleco > data_samples[j,i]
data_samples[j,i]
petel2 <- 0.28
data_samples[j,i]+peteleco
data_samples[j,i]-peteleco
data_samples[j,i]-petel2
data_samples[j,i]+petel2
diff_distrib
any(diff_distrib)<data_samples[j,i]
any(diff_distrib<data_samples[j,i])
peteleco
data_samples[j,i]
data_samples[j,i]
?runif
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
runif(1, min=0, max=data_samples[j,i])
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
data_ts <- ts(data_use[,4:19])
embed_max <- embed_plots(data_ts, emb_dim = 20, trap_name, overwrite =T)
names(embed_max) <- c("species","emax_auto")
simplex_plot(data_ts, emax = embed_max[,2], trap_name, overwrite = T)
smap_plots(data_ts, emax = embed_max[,2], trap_name, overwrite = T)
data <- data_na
list <- distrib_list
data_na_resolution <- data[duplicated(data$open),]
samples_resolution <- as.numeric(as.character(rownames(data_na_resolution)))-1
data_samples <- data[samples_resolution,]
names(data_na_resolution)
i = 16
j = 42
data_samples[j,i]
# time-steps that need to be estimated
data_na_resolution <- data[duplicated(data$open),]
# samples averaged throughout the 14 days
samples_resolution <- as.numeric(as.character(rownames(data_na_resolution)))-1
data_samples <- data[samples_resolution,]
data_samples[,i]
data_na_resolution
j = 5
total_shells <- 2*data_samples[j,i]
data_samples[j,i]
2*data_samples[j,i]
(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]
)
which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
names(list$sums)
names(data_na_resolution)[i]
rows_to_sample
list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]
list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells
which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
list$diffs[rows_to_sample,
]
which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
rows_to_sample <- which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
rows_to_sample
list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
list$diffs[rows_to_sample,which(names(list$sums)
list$diffs[rows_to_sample,
list$diffs[rows_to_sample,
]
list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
diff_distrib <- list$diffs[rows_to_sample,which(names(list$sums) == names(data_na_resolution)[i])]
diff_distrib
which(diff_distrib<data_samples[j,i])
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
sample(diff_distrib,1)
diff_distrib
which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells)
list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]
which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]<=total_shells & list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]!=0)
sum(which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]!=0)))
sum(which(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]!=0))
list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]
sum(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]!=0)
sum(list$sums[,which(names(list$sums)==names(data_na_resolution)[i])]==0)
rm(list=ls())
setwd("/Users/marinacostarillo/Google Drive/PhD/projects")
setwd("./time-series-forams/")
# Libraries
# source("R/library.R")
library(R.utils)   # sourceDirectory function
library(lubridate) # date calculations
library(GGally)    # ggpairs function
library(tseries)   # tests series stationary
library(ggplot2)   # plots
library(reshape)   # function melt
library(corrplot)  # matrix correlation plot
# Auxiliary functions
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
###
### Data
###
trap_name <- c("GOM") # Gulf of Mexico sediment trap
# Creating output folder for this sediment trap
if (!file.exists(paste("output/",trap_name,sep=""))){ dir.create(paste("output/",trap_name,"/",sep=""))}
# Time-series data
if(trap_name == "GOM"){
raw_data <- get_gom_sst(overwrite = F) # gets temperature data for the GOM time-series
raw_data<- raw_data[86:nrow(raw_data),] # removing first part of GOM time-series with big gaps (next_open = 123 and 21)
}# Other sediment traps: else{raw_data <- get_trap_data(overwrite = F)} # still write "get_trap_data" function
# Data to use
data <- raw_data[,-c(2:7)] # or <- datafd
data$open <- ymd(data$open) # transforming to date format (lubridate pkg)
# Plot scatterplot of everything
# ggpairs(data[,2:ncol(data)])
# First differences time-series
datafd <- get_first_diff(raw_data, trap_name, days_closed = 10,overwrite = F)
# days_closed : maximum number of days inbetween samples,if that gap between two samp
library(rEDM)
library(zoo)
###### DATA ######
# GOM_NAs.csv : Gulf of Mexico sediment trap data with continuous time-steps and "NA" for intervals without data, see "README.txt" in data folder
data_na <- read.csv("data/GOM/GOM_NAs.csv", header = T, na = "NA")
# changing format to date
data_na$open <- dmy(data_na$open)
data_na$close <- dmy(data_na$close)
# tranfoming columns into numeric, NA_resolution and NA_gap will be transformed into NA (warnings())
data_na[, c(5:ncol(data_na))] <- sapply(data_na[, c(5:ncol(data_na))], function(x) as.numeric(as.character(x)))
# Calculating the distribution of sums and differences between consecutives samples (less than 'days_closed' apart)
distrib_list <- get_distrib_diffs(data_na, trap_name,  days_closed=7 ,overwrite = F)
# Filling in the NA_resolutions
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = F)
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = T)
i = 15
data_ts <- ts(data_use[,4:19])
# plot(data_ts[,c(2:11)])
# plot(data_ts[,c(12:16)])
# Embedding dimension plot (simplex function rEDM) # Rafa
embed_max <- embed_plots(data_ts, emb_dim = 20, trap_name, overwrite =T)
names(embed_max) <- c("species","emax_auto")
# Optimizing embeding dimension by hand:
# embed_max <- cbind(embed_max, emax = c())
# Simplex prediction and prediction decay
simplex_plot(data_ts, emax = embed_max[,2], trap_name, overwrite = T)
# S-maps: red noise vs. nonlinear deterministic behaviour
# If forecast skill increases for Î¸>0, then the results are suggestive of nonlinear dynamics
smap_plots(data_ts, emax = embed_max[,2], trap_name, overwrite = T)
embed_max
embed_max <- embed_plots(data_ts, emb_dim = 20, trap_name, overwrite =T)
embed_max
embed_max <- embed_plots(data_ts, emb_dim = 20, trap_name, overwrite =T)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
data_use <- estimate_na_resolution(data_na, distrib_list, overwrite = T)
embed_max
embed_max <- cbind(embed_max, emax = c(3,3,5,2,2,2,1,2,2,5,3,10,3,5,5))
embed_max
# Embedding dimension plot (simplex function rEDM) # Rafa
embed_max <- embed_plots(data_ts, emb_dim = 20, trap_name, overwrite =T)
names(embed_max) <- c("species","emax_auto")
# Optimizing embeding dimension by eye and hand:
embed_max <- cbind(embed_max, emax = c(3,3,5,2,2,2,1,2,2,5,3,10,3,5,5))
# worse: G_ruber_pink, N_dutertrei, G_truncatulinoides
embed_max
simplex_plot(data_ts, emax = embed_max$emax, trap_name, overwrite = T)
smap_plots(data_ts, emax = embed_max$emax, trap_name, overwrite = T)
rm(list=ls())
setwd("/Users/marinacostarillo/Google Drive/PhD/projects")
setwd("./time-series-forams/")
# Libraries
# source("R/library.R")
library(R.utils)   # sourceDirectory function
library(lubridate) # date calculations
library(GGally)    # ggpairs function
library(tseries)   # tests series stationary
library(ggplot2)   # plots
library(reshape)   # function melt
library(corrplot)  # matrix correlation plot
# Auxiliary functions
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
###
### Data
###
trap_name <- c("GOM") # Gulf of Mexico sediment trap
# Creating output folder for this sediment trap
if (!file.exists(paste("output/",trap_name,sep=""))){ dir.create(paste("output/",trap_name,"/",sep=""))}
# Time-series data
if(trap_name == "GOM"){
raw_data <- get_gom_sst(overwrite = F) # gets temperature data for the GOM time-series
raw_data<- raw_data[86:nrow(raw_data),] # removing first part of GOM time-series with big gaps (next_open = 123 and 21)
}# Other sediment traps: else{raw_data <- get_trap_data(overwrite = F)} # still write "get_trap_data" function
# Data to use
data <- raw_data[,-c(2:7)] # or <- datafd
data$open <- ymd(data$open) # transforming to date format (lubridate pkg)
# Plot scatterplot of everything
# ggpairs(data[,2:ncol(data)])
# First differences time-series
datafd <- get_first_diff(raw_data, trap_name, days_closed = 10,overwrite = F)
# days_closed : maximum number of days inbetween samples,if that gap between two samples is bigger than 10 days (next_open > 10 days), then the difference between these two samples is not included
# Testing if time-series are stationary (see output/trap_name/stationary_test.csv)
stationary <- test_stationary(data, trap_name, overwrite = F)
# Cross-Correlation (lags)
lags_correlation <- cross_correlation(data, trap_name, overwrite = F)
# Splines and species seasonality
splines <- seasonal_splines(DataSeries = data, DateFormat='%d/%m/%y', SavePlots = F, overwrite = F)
# Correlation and Surrogates
corr_method <- c("kendall")
corr_surrog <- corr_surrogates(data, splines, trap_name, nreps=500, corr_method, overwrite = F)
corr_surrog[1:50,1:15]
random_resid <- list()
random_resid <- lapply(2:ncol(splines), function(i) replicate(nreps, sample(c(data[,i] - splines[,i]), size = length(splines[,i]), replace = FALSE, prob = NULL)))
names(random_resid) <- names(splines)[2:ncol(splines)]
nreps=100
random_resid <- list()
random_resid <- lapply(2:ncol(splines), function(i) replicate(nreps, sample(c(data[,i] - splines[,i]), size = length(splines[,i]), replace = FALSE, prob = NULL)))
names(random_resid) <- names(splines)[2:ncol(splines)]
surrogates <- lapply(1:length(random_resid), function(i){random_resid[[i]] + splines[,i+1]}) # i+1 because first column of splines is "open"
names(surrogates) <- names(random_resid)
corr_pairs <- data.frame()
comb_two <- combn(1:length(surrogates),2)
i=1
col_var1 <- which(names(data)==names(surrogates)[(comb_two[1,i])])
col_var2 <- which(names(data)==names(surrogates)[(comb_two[2,i])])
# correlation of each variable with its own spline (measure of seasonality of the time-series)
season_var1 <- cor(data[,col_var1], splines[,col_var1])
season_var2 <-  cor(data[,col_var2], splines[,col_var2])
# correlations
corr_series <-  cor.test(data[,col_var1], data[,col_var2], method = corr_method)$estimate
corr_series_p <- cor.test(data[,col_var1], data[,col_var2], method = corr_method)$p.value
corr_splines <- cor.test(splines[,col_var1], splines[,col_var2], method = corr_method)$estimate
corr_splines_p <- cor.test(splines[,col_var1], splines[,col_var2], method = corr_method)$p.value
corr_resid <- cor.test((data[,col_var1]-splines[,col_var1]),(data[,col_var2]-splines[,col_var2]),method = corr_method)$estimate
corr_resid_p <- cor.test((data[,col_var1]-splines[,col_var1]),(data[,col_var2]-splines[,col_var2]),method = corr_method)$p.value
# correlations surrogates (null model)
corr_surr <- mapply(function(x, y) cor.test(x, y, method = corr_method)$estimate, as.data.frame(surrogates[[(comb_two[1,i])]]), as.data.frame(surrogates[[(comb_two[2,i])]]))
# correlates column i of the matrices x with column i of matrix y (ncol = nreps = null series)
# corr_surr is then a vector with 'nreps' correlations
corr_surr
str(corr_surr)
sum(corr_surr>0)/100
sum(corr_surr>0)/nreps
sum(corr_surr<0)/nreps
prop_above_0 <- sum(corr_surr>0)/nreps
sum(corr_surr>0)/nreps
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
corr_surrog <- corr_surrogates(data, splines, trap_name, nreps=500, corr_method, overwrite = T)
names(corr_surrog)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
corr_method <- c("kendall")
corr_surrog <- corr_surrogates(data, splines, trap_name, nreps=500, corr_method, overwrite = T)
corr_surrogates_boxplots(corr_surrog, trap_name, overwrite=T)
corr_series
sum(corr_surr>0)/nreps
sum(corr_surr >= corr_series)/nreps
sum(corr_surr <= corr_series)/nreps
corr_surr <= corr_series
corr_surr
corr_series
col_var1
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
corr_surrog <- corr_surrogates(data, splines, trap_name, nreps=500, corr_method, overwrite = T)
corr_surrogates_boxplots(corr_surrog, trap_name, overwrite=T)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
sourceDirectory("./R/aux_functions", modifiedOnly=FALSE)
names(corr_surrog)
str(corr_surrog)
corr_surrogates_boxplots(corr_surrog, trap_name, overwrite=T)
